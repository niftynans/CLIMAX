{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc632aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append('../..')\n",
    "from slime import lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139affaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = load_breast_cancer()\n",
    "train, test, labels_train, labels_test = train_test_split(breast_cancer.data, breast_cancer.target, train_size=0.80)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(train, labels_train)\n",
    "\n",
    "explainer = lime_tabular.LimeTabularExplainer(train, \n",
    "                                              feature_names = breast_cancer.feature_names, \n",
    "                                              class_names = breast_cancer.target_names, \n",
    "                                              discretize_continuous = False, \n",
    "                                              feature_selection = \"lasso_path\", \n",
    "                                              sample_around_instance = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4344f93f",
   "metadata": {},
   "source": [
    "### LIME results in different explantions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598276a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(test[0], rf.predict_proba, num_features = 5, num_samples = 1000)\n",
    "exp.show_in_notebook(show_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cefbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(test[0], rf.predict_proba, num_features = 5, num_samples = 1000)\n",
    "exp.show_in_notebook(show_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7afffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(test[0], rf.predict_proba, num_features = 5, num_samples = 1000)\n",
    "exp.show_in_notebook(show_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c801134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(test[0], rf.predict_proba, num_features = 5, num_samples = 1000)\n",
    "exp.show_in_notebook(show_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8855c88",
   "metadata": {},
   "source": [
    "### S-LIME provides stable explantions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bfa1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.slime(test[0], rf.predict_proba, num_features = 5, num_samples = 1000, n_max = 10000, alpha = 0.05)\n",
    "exp.show_in_notebook(show_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae063da6",
   "metadata": {},
   "source": [
    "### Jaccard index for LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f6ebb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71736842 0.69359649 0.80618421 0.78344862 0.7791698 ]\n"
     ]
    }
   ],
   "source": [
    "explainer = lime_tabular.LimeTabularExplainer(train, \n",
    "                                              feature_names = breast_cancer.feature_names, \n",
    "                                              class_names = breast_cancer.target_names, \n",
    "                                              discretize_continuous = False, \n",
    "                                              feature_selection = \"lasso_path\", \n",
    "                                              sample_around_instance = True)\n",
    "\n",
    "jaccard_lime = []\n",
    "\n",
    "for seed in range(20):\n",
    "    np.random.seed(seed + 1)\n",
    "    i = np.random.randint(0, test.shape[0])\n",
    "    \n",
    "    result = []\n",
    "    for _ in range(20):\n",
    "        exp = explainer.explain_instance(test[i], rf.predict_proba, num_features=5, num_samples = 1000)\n",
    "        result.append([i[0] for i in exp.as_list()])\n",
    "\n",
    "        \n",
    "    jaccard = []\n",
    "    for num in range(1, 6):\n",
    "        temp = []\n",
    "        for j in range(20 - 1):\n",
    "            for k in range(j + 1, 20):\n",
    "                A = result[j][:num]\n",
    "                B = result[k][:num]\n",
    "                temp.append(len(set(A).intersection(set(B))) / float(len(set(A).union(set(B)))))\n",
    "        jaccard.append(np.mean(temp))\n",
    "\n",
    "    jaccard_lime.append(jaccard)\n",
    "    \n",
    "print(np.mean(jaccard_lime, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d832111f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABULAR\n",
      "Counter({1: 1})\n",
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.07244378981133771\n",
      "iter 1 cg iter 0 iter_diff 0.009126643869557739\n",
      "iter 2 cg iter 0 iter_diff 0.000601415664280508\n",
      "iter 3 cg iter 0 iter_diff 7.979953303719845e-06\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.001944\n",
      "         Iterations: 4\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 8\n",
      "         Hessian evaluations: 14\n",
      "TABULAR\n",
      "Counter({1: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n",
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.07956490087960481\n",
      "iter 1 cg iter 0 iter_diff 0.008776026025201425\n",
      "iter 2 cg iter 0 iter_diff 0.00013626867975520443\n",
      "iter 3 cg iter 0 iter_diff 9.60915135959895e-07\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.002173\n",
      "         Iterations: 4\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 8\n",
      "         Hessian evaluations: 13\n",
      "TABULAR\n",
      "Counter({1: 1})\n",
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.08813350568041774\n",
      "iter 1 cg iter 0 iter_diff 0.0069594636072984675\n",
      "iter 2 cg iter 0 iter_diff 0.0005093983671132849\n",
      "iter 3 cg iter 0 iter_diff 3.9482746232708844e-06\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.002372\n",
      "         Iterations: 4\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 8\n",
      "         Hessian evaluations: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n",
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABULAR\n",
      "Counter({1: 1})\n",
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.08375659719788058\n",
      "iter 1 cg iter 0 iter_diff 0.007611249475392116\n",
      "iter 2 cg iter 0 iter_diff 0.0003249115082391025\n",
      "iter 3 cg iter 0 iter_diff 3.5754128005997116e-06\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.002091\n",
      "         Iterations: 4\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 8\n",
      "         Hessian evaluations: 16\n",
      "TABULAR\n",
      "Counter({1: 1})\n",
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.07074471005973255\n",
      "iter 1 cg iter 0 iter_diff 0.006306855652516506\n",
      "iter 2 cg iter 0 iter_diff 0.00015224536518247396\n",
      "iter 3 cg iter 0 iter_diff 9.809692697570474e-07\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.001759\n",
      "         Iterations: 4\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 8\n",
      "         Hessian evaluations: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n",
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABULAR\n",
      "Counter({1: 1})\n",
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.07701105487964303\n",
      "iter 1 cg iter 0 iter_diff 0.00707663302652586\n",
      "iter 2 cg iter 0 iter_diff 0.0001933598893064816\n",
      "iter 3 cg iter 0 iter_diff 9.165455130521025e-07\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.001939\n",
      "         Iterations: 4\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 8\n",
      "         Hessian evaluations: 13\n",
      "TABULAR\n",
      "Counter({1: 1})\n",
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.08536429773331854\n",
      "iter 1 cg iter 0 iter_diff 0.007073562045889973\n",
      "iter 2 cg iter 0 iter_diff 0.00031662950587344754\n",
      "iter 3 cg iter 0 iter_diff 1.7008137816723525e-06\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.002279\n",
      "         Iterations: 4\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 8\n",
      "         Hessian evaluations: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n",
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABULAR\n",
      "Counter({1: 1})\n",
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.08284206146416716\n",
      "iter 1 cg iter 0 iter_diff 0.02304167163218726\n",
      "iter 2 cg iter 0 iter_diff 0.008642757120379228\n",
      "iter 3 cg iter 0 iter_diff 0.000521340068416622\n",
      "iter 4 cg iter 0 iter_diff 1.151172531451913e-05\n",
      "iter 5 cg iter 0 iter_diff 2.5316133129432445e-07\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.001718\n",
      "         Iterations: 6\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 17\n",
      "TABULAR\n",
      "Counter({1: 1})\n",
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.075524235182575\n",
      "iter 1 cg iter 0 iter_diff 0.004677273868458332\n",
      "iter 2 cg iter 0 iter_diff 0.00025102143268436385\n",
      "iter 3 cg iter 0 iter_diff 7.564730670331149e-07\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.001828\n",
      "         Iterations: 4\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 8\n",
      "         Hessian evaluations: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n",
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABULAR\n",
      "Counter({1: 1})\n",
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.08443040498871524\n",
      "iter 1 cg iter 0 iter_diff 0.006481358993795379\n",
      "iter 2 cg iter 0 iter_diff 0.0004926848915405462\n",
      "iter 3 cg iter 0 iter_diff 7.557576474490301e-06\n",
      "iter 4 cg iter 0 iter_diff 1.7251083778610488e-07\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.002171\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 10\n",
      "         Hessian evaluations: 15\n",
      "TABULAR\n",
      "Counter({1: 1})\n",
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.08388732656568414\n",
      "iter 1 cg iter 0 iter_diff 0.0220964503555764\n",
      "iter 2 cg iter 0 iter_diff 0.010818820993504723\n",
      "iter 3 cg iter 0 iter_diff 0.0005115113502305469\n",
      "iter 4 cg iter 0 iter_diff 8.837408759536456e-06\n",
      "iter 5 cg iter 0 iter_diff 5.527555435077668e-07\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.001807\n",
      "         Iterations: 6\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n",
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABULAR\n",
      "Counter({1: 1})\n",
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.0720162477872028\n",
      "iter 1 cg iter 0 iter_diff 0.006408456024087884\n",
      "iter 2 cg iter 0 iter_diff 0.0003929735270402884\n",
      "iter 3 cg iter 0 iter_diff 3.953862871564911e-06\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.001966\n",
      "         Iterations: 4\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 8\n",
      "         Hessian evaluations: 12\n",
      "TABULAR\n",
      "Counter({1: 1})\n",
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.08116701213753633\n",
      "iter 1 cg iter 0 iter_diff 0.008197312562613477\n",
      "iter 2 cg iter 0 iter_diff 0.0005143521854049291\n",
      "iter 3 cg iter 0 iter_diff 1.0326463840038382e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 4 cg iter 0 iter_diff 2.7035577662487195e-07\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.002372\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 10\n",
      "         Hessian evaluations: 15\n",
      "TABULAR\n",
      "Counter({1: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n",
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.08099336209012956\n",
      "iter 1 cg iter 0 iter_diff 0.006086050580026417\n",
      "iter 2 cg iter 0 iter_diff 0.00039859811083091737\n",
      "iter 3 cg iter 0 iter_diff 7.736993391087646e-06\n",
      "iter 4 cg iter 0 iter_diff 2.0407505058874995e-07\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.002011\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 10\n",
      "         Hessian evaluations: 15\n",
      "TABULAR\n",
      "Counter({1: 1})\n",
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.07627140814820378\n",
      "iter 1 cg iter 0 iter_diff 0.0071116282001255846\n",
      "iter 2 cg iter 0 iter_diff 0.000546000412123242\n",
      "iter 3 cg iter 0 iter_diff 1.2242627711220875e-05\n",
      "iter 4 cg iter 0 iter_diff 3.0902444268050486e-07\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.001854\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 10\n",
      "         Hessian evaluations: 15\n",
      "TABULAR\n",
      "Counter({1: 1})\n",
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.0913073225739042\n",
      "iter 1 cg iter 0 iter_diff 0.026091050232213274\n",
      "iter 2 cg iter 0 iter_diff 0.011507499499806062\n",
      "iter 3 cg iter 0 iter_diff 0.0007466534343679207\n",
      "iter 4 cg iter 0 iter_diff 1.941340688910078e-05\n",
      "iter 5 cg iter 0 iter_diff 4.4616484042177794e-07\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.002234\n",
      "         Iterations: 6\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 17\n",
      "TABULAR\n",
      "Counter({1: 1})\n",
      "Succeed in getting the inverse of preconditioner M.\n",
      "iter 0 cg iter 0 iter_diff 0.08353584427208743\n",
      "iter 1 cg iter 0 iter_diff 0.00983666180427821\n",
      "iter 2 cg iter 0 iter_diff 0.0007717799281995172\n",
      "iter 3 cg iter 0 iter_diff 1.9687540416071183e-05\n",
      "iter 4 cg iter 0 iter_diff 1.5653396369920935e-07\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.002463\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 10\n",
      "         Hessian evaluations: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n",
      "/home/pnans/Documents/GitHub/IF_slime/doc/notebooks/../../inverse_hvp.py:142: OptimizeWarning: Unknown solver options: preconditioner\n",
      "  fmin_results = fmin_ncg(f=fmin_loss_fn,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m result \u001b[39m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m20\u001b[39m):\n\u001b[0;32m---> 16\u001b[0m     exp \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mif_explain_instance(test[i], rf\u001b[39m.\u001b[39;49mpredict_proba, num_features\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, num_samples \u001b[39m=\u001b[39;49m \u001b[39m1000\u001b[39;49m)\n\u001b[1;32m     17\u001b[0m     result\u001b[39m.\u001b[39mappend([i[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m exp\u001b[39m.\u001b[39mas_list()])\n\u001b[1;32m     19\u001b[0m jaccard \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/GitHub/IF_slime/doc/notebooks/../../slime/lime_tabular.py:905\u001b[0m, in \u001b[0;36mLimeTabularExplainer.if_explain_instance\u001b[0;34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor, sampling_method)\u001b[0m\n\u001b[1;32m    898\u001b[0m     scaled_data \u001b[39m=\u001b[39m (data \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mmean_) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale_\n\u001b[1;32m    899\u001b[0m distances \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mpairwise_distances(\n\u001b[1;32m    900\u001b[0m         scaled_data,\n\u001b[1;32m    901\u001b[0m         scaled_data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m    902\u001b[0m         metric\u001b[39m=\u001b[39mdistance_metric\n\u001b[1;32m    903\u001b[0m )\u001b[39m.\u001b[39mravel()\n\u001b[0;32m--> 905\u001b[0m yss \u001b[39m=\u001b[39m predict_fn(inverse)\n\u001b[1;32m    907\u001b[0m \u001b[39m# for classification, the model needs to provide a list of tuples - classes\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \u001b[39m# along with prediction probabilities\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/notebook/jupyter_env/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:885\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    880\u001b[0m all_proba \u001b[39m=\u001b[39m [\n\u001b[1;32m    881\u001b[0m     np\u001b[39m.\u001b[39mzeros((X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], j), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    882\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39matleast_1d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_)\n\u001b[1;32m    883\u001b[0m ]\n\u001b[1;32m    884\u001b[0m lock \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mLock()\n\u001b[0;32m--> 885\u001b[0m Parallel(n_jobs\u001b[39m=\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, require\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msharedmem\u001b[39;49m\u001b[39m\"\u001b[39;49m)(\n\u001b[1;32m    886\u001b[0m     delayed(_accumulate_prediction)(e\u001b[39m.\u001b[39;49mpredict_proba, X, all_proba, lock)\n\u001b[1;32m    887\u001b[0m     \u001b[39mfor\u001b[39;49;00m e \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimators_\n\u001b[1;32m    888\u001b[0m )\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m proba \u001b[39min\u001b[39;00m all_proba:\n\u001b[1;32m    891\u001b[0m     proba \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_)\n",
      "File \u001b[0;32m~/notebook/jupyter_env/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/notebook/jupyter_env/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/notebook/jupyter_env/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/notebook/jupyter_env/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/notebook/jupyter_env/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/notebook/jupyter_env/lib/python3.10/site-packages/joblib/parallel.py:287\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m    288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/notebook/jupyter_env/lib/python3.10/site-packages/joblib/parallel.py:246\u001b[0m, in \u001b[0;36mparallel_backend.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mtype\u001b[39m, value, traceback):\n\u001b[0;32m--> 246\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munregister()\n",
      "File \u001b[0;32m~/notebook/jupyter_env/lib/python3.10/site-packages/joblib/parallel.py:250\u001b[0m, in \u001b[0;36mparallel_backend.unregister\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munregister\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mold_backend_and_jobs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(_backend, \u001b[39m'\u001b[39;49m\u001b[39mbackend_and_jobs\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m             \u001b[39mdel\u001b[39;00m _backend\u001b[39m.\u001b[39mbackend_and_jobs\n\u001b[1;32m    252\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "explainer = lime_tabular.LimeTabularExplainer(train, \n",
    "                                              feature_names = breast_cancer.feature_names, \n",
    "                                              class_names = breast_cancer.target_names, \n",
    "                                              discretize_continuous = False, \n",
    "                                              feature_selection = \"lasso_path\", \n",
    "                                              sample_around_instance = True)\n",
    "\n",
    "jaccard_lime = []\n",
    "\n",
    "for seed in range(20):\n",
    "    np.random.seed(seed + 1)\n",
    "    i = np.random.randint(0, test.shape[0])\n",
    "    \n",
    "    result = []\n",
    "    for _ in range(20):\n",
    "        exp = explainer.if_explain_instance(test[i], rf.predict_proba, num_features=5, num_samples = 1000)\n",
    "        result.append([i[0] for i in exp.as_list()])\n",
    "        \n",
    "    jaccard = []\n",
    "    for num in range(1, 6):\n",
    "        temp = []\n",
    "        for j in range(20 - 1):\n",
    "            for k in range(j + 1, 20):\n",
    "                A = result[j][:num]\n",
    "                B = result[k][:num]\n",
    "                temp.append(len(set(A).intersection(set(B))) / float(len(set(A).union(set(B)))))\n",
    "        jaccard.append(np.mean(temp))\n",
    "\n",
    "    jaccard_lime.append(jaccard)\n",
    "    \n",
    "print(np.mean(jaccard_lime, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641de413",
   "metadata": {},
   "source": [
    "### Jaccard index for S-LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61a4e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_tabular.LimeTabularExplainer(train, \n",
    "                                              feature_names = breast_cancer.feature_names, \n",
    "                                              class_names = breast_cancer.target_names, \n",
    "                                              discretize_continuous = False, \n",
    "                                              feature_selection = \"lasso_path\", \n",
    "                                              sample_around_instance = True)\n",
    "\n",
    "jaccard_slime = []\n",
    "\n",
    "for seed in range(20):\n",
    "    np.random.seed(seed + 1)\n",
    "    i = np.random.randint(0, test.shape[0])\n",
    "    \n",
    "    result = []\n",
    "    for _ in range(20):\n",
    "        exp = explainer.slime(test[i], rf.predict_proba, num_features=5, num_samples = 1000, n_max = 20000, alpha = 0.05)\n",
    "        result.append([i[0] for i in exp.as_list()])\n",
    "        \n",
    "    jaccard = []\n",
    "    for num in range(1, 6):\n",
    "        temp = []\n",
    "        for j in range(20 - 1):\n",
    "            for k in range(j + 1, 20):\n",
    "                A = result[j][:num]\n",
    "                B = result[k][:num]\n",
    "                temp.append(len(set(A).intersection(set(B))) / float(len(set(A).union(set(B)))))\n",
    "        jaccard.append(np.mean(temp))\n",
    "\n",
    "    jaccard_slime.append(jaccard)\n",
    "    \n",
    "print(np.mean(jaccard_slime, axis = 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "45263783c026738a01229a76a997ac4b06d8d9e82a135e1f5eb2b8b0ed62292e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
